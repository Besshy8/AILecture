## $Column\sim$ リッジ回帰と正則化 $\sim$

重回帰の正規方程式は、

$$\vec{w} = (X^TX)^{-1}X^T\vec{y} \tag{C.1.2.1}$$

であることをみた。この式についてもう少し考える。

今、$X^TX$に注目すると、この行列は正方行列となっている。$D\times D$正方行列であるとすると、式($C.1.2.1$)はこの正方行列の逆行列を含んでいることがわかる。しかし、一般的にある行列が逆行列を持つことは自明ではないし、逆行列を持っていたとしても計算が不安定になる場合がある。次の例をみてみよう。

$$X = \begin{pmatrix}
1 & 2 & 4 \\
1 & 3 & 6.1 \\
1 & 4 & 7.9
\end{pmatrix}\tag{C.1.2.2}$$

この場合、$(X^TX)^{-1}$を考えると以下のようになる。

$$(X^TX)^{-1} = \begin{pmatrix}
6.33 & 18.00 & -10.00 \\
18.00 & 254.00 & -130.00 \\
-10.00 & -130.00 & 66.67
\end{pmatrix}\tag{C.1.2.3}$$

このように$D\times D$正方行列$(X^TX)^{-1}$の各要素は絶対値が非常に大きくなってしまうことがわかる。式$(C.1.2.1)$を考えると、これによって計算
される$\vec{w}$も当然大きくなることが予想される。図1,2(1-2_Column図表.pdf参照)を見るとわかるように
重み$\vec{w}$の要素が大きくなればなるほど、予測値がデータの違いに過敏に
反応するようになり、正しい学習結果を得ることができない。このような状況を
機械学習の分野では、「過学習」と呼ぶ。

この過学習を防ぐのによく使われる手法として、「正則化」というものがある。これは誤差関数$E$に係数ベクトルの大きさ$|\vec{w}|^2 = \vec{w}^T\vec{w}$を加えた以下の式を最小化する。

$$E = (\vec{y} - X\vec{w})^T(\vec{y} - X\vec{w}) + \alpha \vec{w}^T\vec{w},\qquad \alpha \geq 0\tag{C.1.2.4}$$

この式から正規方程式を導くと、

$$(X^TX + \alpha I)\vec{w} = X^T\vec{y}\tag{C.1.2.5}$$
$$\vec{w} = (X^TX + \alpha I)^{-1}X^T\vec{y}\tag{C.1.2.6}$$

となる。すると、$(X^TX + \alpha I)^{-1}$は先ほどの例でいくと、$\alpha = 0.1$として、

$$(X^TX + 0.1 \times I)^{-1} = \begin{pmatrix}
3.34 & 0.16 & -0.60 \\
0.16 & 7.70 & -3.88 \\
-0.60 & -3.88 & 2.04
\end{pmatrix} \tag{C.1.2.7}$$

となって逆行列の値が$+ \alpha I$の項によって安定していることがわかる。式$(C.1.2.6)$のような係数の求め方を回帰分析の分野では「リッジ回帰」と呼ぶ。

また、次にように完全に列の定数倍になっている場合、

$$X = \begin{pmatrix}
1 & 2 & 4 \\
1 & 3 & 6 \\
1 & 4 & 8
\end{pmatrix} \tag{C.1.2.8}$$

を考える。この場合は、$D\times D$正方行列$X^TX$のランクが$\rm rank(X^TX) \leq D$となり、ランク落ちしてしまうので、逆行列の計算がそもそもできない。(説明変数の数$D$が、データ点の数$N$より多い(背が低く幅広な行列)ことが原因でランク落ちすることもある。)こういう場合も、リッジ回帰を使えば、$+\alpha I$の項のおかげで行列の退化(ランクが足りないこと)を防げ、逆行列を計算することが可能になる。なお、リッジ回帰を使わない場合は、「一般化逆行列」というものを使って本来計算できない
行列の逆行列を計算することができるが、この場合も結果は不安定なものに陥りやすい。(一般化逆行列はさらに発展的な内容なため割愛。)


(補足)
式$(C.1.2.2)$のデータは3列目が2列目の(ほぼ)定数倍になっている。このように
考えている$x_1,x_2,...$(回帰分析の分野では説明変数と呼ぶ)の間に強い
相関がある場合、学習をうまく行うことができず不安定な結果に陥る。このような
状況は「多重共線性」と呼ばれている。このような状況は、説明変数をむやみやたらに増やすと当然起こりやすくなるので、多項式の項数や次数を増やす際には注意
が必要である。


