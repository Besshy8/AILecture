# Pythonを用いた初心者向けAI実践講座(中級編) 10/12 配布資料

## 1-1 線形代数

　線形代数は、機械学習だけでなくありとあらゆる分野（工学、経済学等）で
現れる分野である。機械学習の分野では主に、複雑なデータを表現するための
道具として使われることが多い。1-1では準備体操として
行列の基本的な演算と便利な性質を見ていく。

### 1-1-1 ベクトル、行列とは

　ベクトルの例

$$
\vec{a} = \begin{pmatrix}
1  \\
2 \\
3
\end{pmatrix}, \quad
\vec{e} = \begin{pmatrix}
1  \\
0 \\
0
\end{pmatrix},
\tag{1.1.1}$$

　行列の例

$$
A = \begin{pmatrix}
1 & 2 \\
3 & 4
\end{pmatrix}, \quad
B = \begin{pmatrix}
2 & 3 \\
4 & 5
\end{pmatrix}, \quad
I = \begin{pmatrix}
1 & 0 & 0 \\ 
0 & 1 & 0 \\
0 & 0 & 1
\end{pmatrix}
\tag{1.1.2}$$

### 1-1-2 基本的な演算

　行列の和

$$A + B = \begin{pmatrix}
1 & 2 \\
3 & 4
\end{pmatrix} 
+ \begin{pmatrix}
2 & 3 \\
4 & 5
\end{pmatrix}
= \begin{pmatrix}
3 & 5 \\
7 & 9
\end{pmatrix}\tag{1.1.3}$$

　行列の積

$$AB = \begin{pmatrix}
1 & 2 \\
3 & 4
\end{pmatrix} 
\begin{pmatrix}
2 & 3 \\
4 & 5
\end{pmatrix}
= \begin{pmatrix}
1\times2 + 2\times4 & 1\times3 + 2\times5\\
3\times2+4\times4 & 3\times3+4\times5
\end{pmatrix}
$$
$$
= \begin{pmatrix}
10 & 13 \\
22 & 29
\end{pmatrix}
\tag{1.1.4}$$

(注意) 一般的に行列において$AB \neq BA$である。

\clearpage

### 1-1-3 逆行列

　行列$A$を

$$
A = \begin{pmatrix}
a & b \\
c & d
\end{pmatrix}
\tag{1.1.5}$$

として次の量$A^{-1}$を行列$A$の逆行列と呼び、以下のように定義する。

$$A^{-1} = \frac{1}{ad-bc}\begin{pmatrix}
d & -b \\
-c & a
\end{pmatrix}
\tag{1.1.6}$$

($3\times3$以上の行列の逆行列の求め方は多少複雑なのでここでは割愛。)

### 1-1-4 転置

　ベクトル、行列計算で重要な操作の1つにその行列の「転置」をとるというものがある。
行列$A$の転置を$A^T$として以下のように表す。

$$A^T = \begin{pmatrix}
a & c \\
b & d
\end{pmatrix}\tag{1.1.7}$$

ベクトルの場合は、与えられたベクトルを以下のように横に倒した形で表記すれば良い。(元のベクトルは列ベクトル、それを横に倒したものは行ベクトルと
呼ばれている。)

$$
\vec{a} = \begin{pmatrix}
1  \\
2 \\
3
\end{pmatrix}, \qquad
\vec{a}^T = (1,2,3)
\tag{1.1.8}$$

### 1-1-5 対称行列

　$n \times n$行列（以下は全て$n \times n$行列の議論である）において

$$A=A^{T} \tag{1.1.9}$$

が成立するとき、その行列を対称行列と呼ぶ。


### 1-1-6 行列式

　行列$A$を

$$
A = \begin{pmatrix}
a & b \\
c & d
\end{pmatrix}
\tag{1.1.5}$$

として次の量$det(A)$を行列$A$の行列式と呼び、以下のように定義する。

$$det(A)= ad - bc\tag{1.1.10}$$


### 1-1-7 内積、1次形式、2次形式
　ベクトルの内積を次のように表記する。

$$f = (\vec{a},\vec{x}) \tag{1.1.11}$$

ただし、ベクトル$\vec{a}$, $\vec{x}$は

$$\vec{a} = (a_1,a_2,...,a_n)^T,\qquad \vec{x} = (x_1,x_2,...x_n)^T\tag{1.1.12}$$

とし、$f$を以下のようにする。

$$f = a_1x_1 + \cdots + a_nx_n = \sum_{i=1}^{n}a_ix_i\tag{1.1.13}$$

変数の1次の項のみからなる式を1次形式という。変数の2次の項のみからなる式も
あり、これを2次形式と呼び、以下のようになる。

$$f=a_{11}x_{1}^2+a_{22}x_{2}^{2}+\cdots+a_{nn}x_{n}^2 
+2a_{12}x_{1}x_{2}+2a_{13}x_{1}x_{3}+\cdots+2a_{(n-1)n}x_{n-1}x_{n}\\
=\sum_{i,j=1}^{n}a_{i,j}x_ix_j\tag{1.1.14}$$

これを（1.1.11）のように内積表記すれば、

$$f = (\vec{x},A\vec{x})\tag{1.1.15}$$

となる。ただし$A$は対称行列である。

(1) 任意のベクトル$\vec{x},\vec{y}$,行列$A$に対して、$(A\vec{x},\vec{y})=(\vec{x},A^{T}\vec{y})$ が成立することを示せ。

(略解)
$$(\vec{x},A^T\vec{y})=\sum_{i=1}^nx_i\Bigl(\sum_{j=1}^{n}a_{ji}y_i\Bigl) = \sum_{i,j=1}^{n}a_{ji}x_iy_j=\sum_{j=1}^{n}\Bigl(\sum_{i=1}^{n}a_{ji}x_i\Bigl)y_j=(A\vec{x},\vec{y})\tag{1.1.16}$$

(2) 任意の$n \times n$の行列$A,B$に対して$(AB)^T=B^{T}A^{T}$が成立することを示せ。

\clearpage

### 1-1-8 行列の微分 (重要)
　行列の微分は機械学習で頻繁に登場する。代表的な微分方法として以下の1次形式と2次形式の2つの微分
方法をおさえておけば良い。

$$\frac{\partial}{\partial \vec{w}} \vec{w}^T\vec{x} = (x_1,x_2,...,x_D)^T = \vec{x}\tag{1.1.17}$$
$$\frac{\partial}{\partial \vec{w}}\vec{w}^TA\vec{w} = A\vec{w} + A^T\vec{w} = (A + A^T)\vec{w}\tag{1.1.18}$$

### 1-1-9 線形結合と1次独立

　$c_1,c_2,..,c_n$を定数、$\vec{a}_1,\vec{a}_2,..,\vec{a_n}$を
ベクトルとして、以下の等式、

$$c_1\vec{a}_1+c_2\vec{a}_2+ \cdots +c_n\vec{a}_n = 0\tag{1.1.19}$$

を満たす$c_1,c_2,..,c_n$が、

$$c_1 = c_2 = ... = c_n = 0\tag{1.1.20}$$

のみであるとき、$\vec{a}_1,\vec{a}_2,..,\vec{a_n}$は1次独立である。(そうでない場合は1次従属と呼ばれる。)

### 1-1-10 固有値、固有ベクトル

　ベクトルに行列をかけることは幾何学的にはそのベクトルが回転することに対応する。大抵のベクトルは行列$A$をかけると予期しない方向に回転するが、ここで
行列$A$を作用させてもベクトルの向きが変化しない（$A$に固有な）特別なベクトル
を考える。このベクトルを$\vec{u}$,ベクトルの拡大率を$\lambda$とすると、


$$A\vec{u}=\lambda\vec{u}\tag{1.1.21}$$

とかける。この$\vec{u}$を固有ベクトル、$\lambda$を固有値という。

式（1.1.21）から単純な式変形で以下の方程式、

$$det|A-\lambda I| = 0\tag{1.1.22}$$

を利用すれば$A$の固有値、固有ベクトルが求まることがわかる。

（3）以下の行列$A$の固有値、固有ベクトルを求めよ。

$$A=\begin{pmatrix}
3 & 1 \\
2 & 2
\end{pmatrix}$$

### 1-1-11 行列の対角化 
　行列には「対角化」という操作があり、機械学習にかかわらず工学的に広く
応用されている。
$A$に$n$個の独立な固有ベクトル$\vec{x_1}\cdots\cdots\vec{x_n}$があればそれらは$S$の列に入り、以下のように対角化される。

$$\Lambda=S^{-1}AS\tag{1.1.23}$$


（4）$\Lambda=S^{-1}AS$を利用し、$A^{n}$を求めよ。

(略解)  $(S^{-1}AS)^n = S^{-1}ASS^{-1}AS...S^{-1}ASS^{-1}AS=S^{-1}A^nS,$よって、$A^{n} = S(S^{-1}AS)^nS^{-1}=S\Lambda^nS^{-1}$

　上記問で、対角化を用いて$A^{n}$を求めたが、これは行列微分方程式や、
フーリエ変換と行った工学上重要な分野で利用されている。

### 1-1-12 対称行列の対角化

　固有値が重複することによって固有ベクトルが足りなくなることがある。このとき
行列$A$の対角化は不可能になってしまう。しかし、対称行列の場合には、必ず
対角化することが可能であり、$A$の要素が全て実数（実対称行列）なら、

1. 固有値が全て実数
2. 固有ベクトルも（都合がいいことに）必ず全て直交

という性質を持つ。

(5) 実対称行列の全ての固有値が実数であることを示せ。

(略解) $A\vec{x} = \lambda\vec{x}$の両辺の複素共役をとり、$A\bar{\vec{x}} = \bar{\lambda}\bar{\vec{x}}$、これを転置して$\bar{\vec{x}}^TA = \bar{\vec{x}}^T\bar{\lambda}$。$A\vec{x} = \lambda\vec{x}$に対して$\bar{\vec{x}}$との内積、$\bar{\vec{x}}^TA = \bar{\vec{x}}^T\bar{\lambda}$に対して$\vec{x}$との内積を考えると、

$$\bar{\vec{x}}^TA\vec{x} = \bar{\vec{x}}^T\lambda\vec{x},\qquad\bar{\vec{x}}^TA\vec{x} = \bar{\vec{x}}^T\bar{\lambda}\vec{x}\tag{1.1.24}$$

よって$\lambda = \bar{\lambda}$


(6) 実対称行列の異なる$\lambda$に対応する固有ベクトルは
必ず直交することを示せ。

(略解) $A\vec{x} = \lambda_1\vec{x},A\vec{y} = \lambda_2\vec{y}$とし、$\lambda_1\neq\lambda_2$とする。

$$(\lambda_1\vec{x})^T\vec{y} = (A\vec{x})^T\vec{y} = \vec{x}^{T}A^{T}\vec{y} = \vec{x}^TA\vec{y}=\vec{x}^T\lambda_2\vec{y}\tag{1.1.25}$$

よって、$\vec{x}^T\lambda_1\vec{y}=\vec{x}^T\lambda_2\vec{y},\lambda_1\neq\lambda_2$より、$\vec{x}^T\vec{y}=0$

　2.の性質を利用し、固有ベクトルを正規直交するように定数倍すると、
(1.1.23)の対角化をさらに簡単に行うことができる。

（スペクトル定理）全ての対称行列は、実数固有値からなる$\Lambda$と
正規直交する固有ベクトルからなる$S=Q$を用いて

$$A=Q\Lambda Q^{T}\tag{1.1.26}$$

と分解される。ここで$Q$は直交行列と呼ばれ、以下の性質を満たす。
（これは物理、工学の分野では主軸定理と呼ばれている。）

$$q_iq_j=\delta_{i,j}\tag{1.1.27}$$

$$
    \delta_{i,j} =
        \begin{cases}
            1 & i = j \\
            0 & i \neq j
        \end{cases}\tag{1.1.28}
$$

$$Q^{-1} = Q^{T}\tag{1.1.29}$$

これらの性質から対称行列は工学上よく利用される。


一部文献では、以下のような表記も行われることがある。

$$A = \lambda_1\vec{x_1}\vec{x_1}^T + \lambda_1\vec{x_1}\vec{x_1}^T + \cdots + \lambda_n\vec{x_n}\vec{x_n}^T\tag{1.1.30}$$


（注意）固有値が重複した場合、固有ベクトルが足りず対角化不可能のように思われるが、
対称行列においては重複した固有値にはその重複度分の独立な固有ベクトルが存在することが
保証される。（証明割愛）これらは互いに直交していないことが多いが、
シュミットの直交化を用いて、独立なベクトルを正規直交するベクトルに
取り直すことができるので、結局全ての固有ベクトルを直交するようにとる
ことができる。

(補足) 対称行列以外の行列は固有値が重複した場合、固有ベクトルが足りず対角化不可能な場合がある。その場合は、「ジョルダン標準形」と呼ばれる可能な
限り対角行列に近い行列を作るというアプローチをとるのが一般的である。

### 1-1-13 2次形式の標準形
　２次形式で表される2変数の2次関数

$$ax^2+2bxy+cy^2=1\tag{1.1.31}$$

を考える。これは（傾いた）楕円を表す。$x,y$に行列$U$を作用し、

$$\vec{x}=U\vec{\tilde{x}}\tag{1.1.32}$$

とする。このとき2次形式の内積と対称行列の対角化を利用すると以下のように
なる。

$$(\vec{x},A\vec{x})=(U\vec{\tilde{x}},AU\vec{\tilde{x}})=(\vec{\tilde{x}},U^{T}AU\vec{\tilde{x}}) = (\vec{\tilde{x}},\Lambda\vec{\tilde{x}}) \\
= \lambda_1\tilde{x_1}^2+\lambda_2\tilde{x_2}^2+\cdots+\lambda_n\tilde{x_n}^2\tag{1.1.33}$$

これを2次形式の標準形と呼ぶ。これは元々の楕円$(\vec{x},A\vec{x})$を回転させ、新しい軸の方向に長軸、短軸をとることが
できることを意味している。

　$\lambda_1,\lambda_2,\cdots\lambda_n$が正の値をとるとき、
$(\vec{x},A\vec{x}) > 0$となる。固有値が全て正の値をとる行列$A$の
ことを正定値行列と呼び、このとき行列$A$は、$(\vec{x},A\vec{x}) > 0$
を満たす。またこの形式の2次曲面、

$$f(x,y)=ax^2+2bxy+cy^2\tag{1.1.34}$$

を考えると（1.1.34）より、

$$(\vec{x},A\vec{x})= \lambda_1\tilde{x_1}^2+\lambda_2\tilde{x_2}^2\tag{1.1.35}$$

であり、$\lambda_1 > 0,\lambda_2 > 0$のとき、この2次曲面は唯一の
最小値を持つはずである。このことから、2次曲面が最小値（または最大値）を
持つか持たないか（これはたびたび機械学習の分野で話題になる）は、
2次形式$(\vec{x},A\vec{x})$で式を表した際の行列$A$が正定値行列か（
もしくは負定値行列か）どうかを求めれば判定することができる。
