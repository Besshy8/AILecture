# Pythonを用いた初心者向けAI実践講座(中級編) 12/21 配布資料

## 2-4 近似推論

事後分布、周辺尤度、予測分布など問題によっては解析的に解くことが難しい
ものに関しては、近似的に解を求めることが多い。近似手法は大きく分けると、サンプリング、変分法に大別される。

### 2-4-1 ギブスサンプリング

分布全体の解析的な把握が難しい場合、期待値等の分布に関する部分的な統計
量を解析することは重要である。そのような各種統計量を得たい場合、分布
から複数の実現値をサンプリングし、その実現値を元に計算を行うことが
有効的である。

$$z_1^{(i)},z_2^{(i)},z_3^{(i)} \sim \ p(z_1,z_2,z_3)$$

混合モデル等、複雑なモデルに関しては全てのサンプルを上記のように同時に
サンプルすることは難しいため、ギブスサンプリングという手法を用いて以下の
ようにサンプリングを行う。

$$z_1^{(i)} \sim \ p(z_1|z_2^{(i-1)},z_3^{(i-1)})$$
$$z_2^{(i)} \sim \ p(z_2|z_1^{(i)},z_3^{(i-1)})$$
$$z_3^{(i)} \sim \ p(z_3|z_1^{(i)},z_2^{(i)})$$

この手法はMCMC（マルコフ連鎖モンテカルロ法）の手法の一つに分類されており、
サンプル数が十分に多い場合、繰り返しで得られた$z_k$は真の事後分布から
得られたものであると理論的に保証されている。（$Column$参照）


（1）ギブスサンプリングを用いて、（）で求めたポアソン混合モデルの
事後分布$p(S,\vec{\lambda},\vec{\pi}|X)$からサンプリングを行う
アルゴリズムを導け。混合分布では以下のように、潜在変数とパラメータを次の
ように分けてサンプリングすると簡単な確率分布が得られることが知られている。

$$S \sim p(S|X,\vec{\lambda},\vec{\pi}), \quad \vec{\lambda}, \ \vec{\pi} \sim p(\vec{\lambda},\vec{\pi}|X,S)$$

\clearpage

### 2-4-2 平均場近似(変分推論)

複雑な分布を最適化問題を解くことによってより簡単な近似分布で表現する手法を「変分推論」、「変分近似」と呼ぶ。事後分布は解析的に解けなくなる状況に陥ることがあるため、確率変数に特定の制約を付けた上で事後分布を近似する。

最適化にはKLダイバージェンスを使い、最小化問題として以下のように定式化される。


$$q_{opt} = argmin_q KL[q(z_1,z_2,z_3) | \ p(z_1,z_2,z_3)]$$

ここで、解が$q_{opt}(z_1,z_2,z_3) = p(z_1,z_2,z_3)$とならないように$q$に制約
をつける手法として、各確率変数に独立性の仮定をおく。

$$p(z_1,z_2,z_3) \approx q(z_1)q(z_2)q(z_3)$$

これを「平均場近似」と呼ぶ。

（2）平均場近似を用いて、（）で求めたポアソン混合モデルの変分推論アルゴリズム
を導出せよ。ただし、事後分布$p(S,\vec{\lambda},\vec{\pi}|X)$
の潜在変数とパラメータを以下のように分けて近似せよ。

$$p(S,\vec{\lambda},\vec{\pi}|X) \approx q(S)q(\vec{\lambda},\vec{\pi})$$

